# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CkBPHLblWSX8t9BHpONv-XkTZ0c3kKt1

# **Predictive Analytics - Prediksi Obesitas**

## Deskripsi Proyek

Proyek ini bertujuan untuk memprediksi tingkat obesitas berdasarkan berbagai fitur. Dataset akan digunakan untuk melatih beberapa model machine learning, termasuk Decision Tree, XGBoost, Random Forest, SVM, Logistic Regression, LightGBM. Hasil dari model-model tersebut akan dibandingkan dan dievaluasi untuk memilih model yang paling tepat dalam memprediksi tingkat obesitas dengan metrik-metriknya.

*Dataset yang digunakan pada proyek ini:*  
https://www.kaggle.com/competitions/playground-series-s4e2/data

| **Variable**                  | **Description**                                 | **Variable**        | **Description**                          |
|:------------------------------|:------------------------------------------------|:--------------------|:-----------------------------------------|
| **ID**                        | Unique identifier                               | **NCP**             | Number of main meals                     |
| **Gender**                    | Gender                                          | **CAEC**            | Consumption of food between meals        |
| **Age**                       | Age (years)                                     | **SMOKE**           | Smoker or not                            |
| **Height**                    | Height (meters)                                 | **CH2O**            | Consumption of water daily               |
| **Weight**                    | Weight (kilograms)                              | **SCC**             | Calories consumption monitoring          |
| **family_history_with_overweight** | Family history of overweight            | **FAF**             | Physical activity frequency              |
| **FAVC**                      | Frequent consumption of high caloric food       | **TUE**             | Time using technology devices            |
| **FCVC**                      | Frequency of consumption of vegetables          | **CALC**            | Consumption of alcohol                   |
| **MTRANS**                    | Transportation used                             | **NObeyesdad**     | Obesity level deducted                   |

## Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

import warnings
warnings.filterwarnings("ignore")

"""## Data Understanding

### Gathering Data
"""

train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

train.head(3)

test.head(3)

"""menampilkan 3 data pada train.csv dan test.csv” memang akurat karena sesuai dengan hasil dan fungsi dari .head(3) pada masing-masing dataframe

### Assessing Data

#### Dataset Information
"""

train.shape

"""Dataset train memiliki 20758 baris (data) dan 18 kolom (fitur/variabel).


"""

train.info()

"""Semua kolom memiliki 20758 non-null, artinya tidak ada nilai yang hilang di seluruh kolom.

#### Checking Missing Value
"""

print("Is there any missing values?")
train.isna().any()

"""Dataset train berisi 20758 data dan 18 kolom.

Semua data lengkap, tidak ada nilai yang kosong/missing.

Data terdiri dari tipe numerik dan kategorikal.

#### Checking Duplicate Data
"""

print("The number of duplicated data:", train.duplicated().sum())

"""Tidak terdapat data duplikat

#### Checking Outlier Data
"""

def detect_outliers(train, test, numeric_columns):
    outlier_info = {'Training Set': {}, 'Testing Set': {}}

    for dataset_name, dataset in [('Training Set', train), ('Testing Set', test)]:
        for column in numeric_columns:
            # Hitung Q1, Q3, dan IQR
            Q1 = dataset[column].quantile(0.25)
            Q3 = dataset[column].quantile(0.75)
            IQR = Q3 - Q1

            # Hitung batas atas dan bawah
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            # Identifikasi outlier
            outliers = dataset[(dataset[column] < lower_bound) | (dataset[column] > upper_bound)][column]

            outlier_info[dataset_name][column] = {
                'jumlah_outlier': len(outliers),
                'persentase_outlier': (len(outliers) / len(dataset)) * 100,
                'batas_bawah': lower_bound,
                'batas_atas': upper_bound,
                'nilai_minimum': dataset[column].min(),
                'nilai_maksimum': dataset[column].max()
            }

            # Box plot
            plt.figure(figsize=(10, 6))
            sns.boxplot(x=dataset[column])
            plt.title(f'Box Plot {column} - {dataset_name}')
            plt.show()

    return outlier_info

numeric_columns = ['Age', 'Height', 'Weight', 'NCP', 'CH2O', 'FAF', 'TUE']

outlier_results = detect_outliers(train, test, numeric_columns)

print("\nInformasi Outlier Training Set:")
print(pd.DataFrame(outlier_results['Training Set']).T)

print("\nInformasi Outlier Testing Set:")
print(pd.DataFrame(outlier_results['Testing Set']).T)

"""> Mendefinisikan fungsi detect_outliers yang menerima tiga argumen:

*   train: dataset pelatihan.
*   test: dataset pengujian
*   numeric_columns: daftar kolom numerik yang ingin dianalisis outlier-nya.

> outlier_info

dictionary untuk menyimpan informasi outlier dari masing-masing dataset.


> Insight:

Menyediakan struktur awal untuk menyimpan statistik outlier secara terpisah antara training dan testing.

> Iterasi Dataset dan Kolom

*   Melakukan iterasi terhadap kedua dataset (train dan test) serta setiap kolom numerik di dalamnya.
* Memastikan proses pengecekan outlier dilakukan untuk semua kolom numerik di kedua dataset secara sistematis.


> Hitung Statistik IQR dan Batas Outlier


* Menghitung kuartil pertama (Q1), kuartil ketiga (Q3), dan Interquartile Range (IQR).
* Menentukan batas bawah dan atas untuk mendeteksi outlier berdasarkan metode IQR.
* Nilai-nilai di bawah lower_bound atau di atas upper_bound dianggap sebagai outlier secara statistik
*   List item

> Identifikasi dan Simpan Informasi Outlier

*   Menentukan baris-baris yang mengandung outlier.
*   Menyimpan informasi lengkap:
    *   Jumlah dan persentase outlier.
    *   Batas bawah dan atas.
    *   Nilai minimum dan maksimum aktual dari kolom tersebut.
*   Dapat mengetahui kolom mana yang memiliki penyimpangan signifikan dan seberapa besar proporsinya.



> Visualisasi Outlier dengan Boxplot


*   Membuat visualisasi box plot untuk setiap kolom numerik.
*   Visual membantu mengenali outlier secara cepat melalui titik-titik yang menyimpang dari kotak plot.
*   Bisa langsung melihat distribusi data dan sebaran outlier secara visual — penting untuk pengambilan keputusan pembersihan data.



> Pemanggilan Fungsi dan Cetak Hasil


*   Menentukan kolom numerik yang akan dianalisis.
*   Memanggil fungsi detect_outliers.
*   Mencetak hasil analisis dalam bentuk dataframe agar rapi dan mudah dibaca.
*   Menyajikan ringkasan statistik outlier untuk masing-masing kolom dan dataset.
*   Memberikan dasar untuk melakukan pembersihan data (misalnya, menghapus atau menangani outlier secara khusus).

#### Statistic Description
"""

# summary statistics
train.describe().transpose()

"""> Menampilkan ringkasan statistik untuk kolom numerik dalam bentuk transpose, agar lebih mudah dibaca per fitur (baris = fitur, kolom = statistik).

*   mean: Rata-rata nilai
*   count: Jumlah data non-null per kolom
*   std: Standar deviasi (penyebaran data)
*   min / max: Nilai minimum dan maksimum
*   25% / 50% / 75%: Kuartil pertama (Q1), median (Q2), dan kuartil ketiga (Q3)
*   Kolom Weight memiliki rentang yang sangat lebar dari 0.0 hingga 173.0, ini  
    bisa mengindikasikan adanya outlier
*   Kolom TUE rata-ratanya sangat kecil (~0.0167) dan memiliki rentang sempit
    (0 hingga 2), bisa jadi kategori.

### Exploratory Data Analysis (EDA)

#### 1. Correlation Matrix
"""

corr = train.select_dtypes("number").corr()

sns.heatmap(corr, annot=True, cmap="RdBu")
plt.title("Correlation Matrix")
plt.show()

"""> Penjelasan Kode:

1.   sns.heatmap(corr, annot=True, cmap="RdBu"):
     *   LMenampilkan heatmap (peta panas) dari matriks korelasi corr.
     *   annot=True: Menampilkan angka korelasi di dalam kotak.
    *   cmap="RdBu": Menggunakan skema warna dari merah ke biru (baik untuk membedakan korelasi negatif vs positif).

2.   plt.title("Correlation Matrix"):
    *   Memberi judul pada plot agar lebih informatif.
3.  plt.show():



> Hasil Heatmap Korelasi

menampilkan matriks korelasi antar fitur numerik dalam dataset, termasuk:


*   Age, Height, Weight, FCVC, NCP, CH2O, FAF, TUE.

Matriks korelasi ini memperlihatkan sejauh mana hubungan linier antara dua variabel. Nilainya berkisar dari:
*   +1: korelasi sempurna positif.
*   -1: korelasi sempurna negatif.
*   0: tidak ada korelasi linier.


> Insight:


1. Height dan Weight → korelasi 0.42
   *   Korelasi positif moderat.
   *   Masuk akal: orang tinggi cenderung berat badannya lebih besar.
   *   Tapi nilai 0.42 menunjukkan tidak terlalu tinggi, jadi tidak berlebihan berkaitan.


2. Weight dan FAF (frekuensi aktivitas fisik) → korelasi -0.085
   *   Korelasi negatif sangat lemah.
   *   Artinya semakin sering olahraga (FAF naik), berat badan cenderung turun, meskipun pengaruhnya kecil.

3. CH2O (konsumsi air) dan FAF → korelasi 0.083
   *   Korelasi kecil positif.
   *   Bisa mencerminkan gaya hidup sehat: orang yang sering olahraga juga lebih banyak minum air.


4. Mayoritas nilai korelasi rendah (< 0.3)
   *   Ini baik karena menunjukkan bahwa sebagian besar fitur relatif independen.
   *  Ini bagus untuk model seperti decision tree, random forest, atau XGBoost yang tidak sensitif terhadap korelasi tinggi.

#### 2. Data Distibution
"""

train.hist(bins=50, figsize=(20,15))
plt.show()

"""

> Penjelasan Kode:

1.   train.hist(bins=50, figsize=(20,15)):
     *   Membuat histogram untuk setiap kolom numerik dalam DataFrame train.
     *   bins=50: Memecah rentang data menjadi 50 interval (semakin banyak bin, semakin detail bentuk distribusinya).
     * figsize=(20,15): Ukuran keseluruhan grid plot agar terlihat jelas.
2.   plt.show():
     *   Menampilkan semua plot secara bersamaan.


1.    id
    *   Distribusi seragam (flat).
    *   Tidak informatif karena hanya ID unik → tidak berguna untuk prediksi, bisa di-drop.
2.   Age
    *   Distribusi positif skew (condong ke kiri).
    *   Banyak individu berusia 15–30 tahun, sangat sedikit yang >40.
    * Bisa jadi indikator penting, tapi mungkin perlu transformasi log jika digunakan dalam model sensitif distribusi.
3. Height
   *   Terdistribusi cukup normal (simetris).
   *   Puncaknya di sekitar 1.65–1.75 meter.
   *   Tidak ada nilai ekstrem mencolok.
4. Weight
  *   Terlihat multi-modal (banyak puncak) → bisa menunjukkan adanya sub-kelompok dalam data (misal kategori gender, atau berat badan ideal/obesitas).
  *   Ada nilai >140 yang bisa jadi outlier.
5. FCVC (Frekuensi Konsumsi Sayur)
  *   Banyak data di nilai maksimum (3.0).
  *   Mungkin karena banyak responden memberi jawaban ekstrem (makan sayur sangat sering).
  * Bisa jadi fitur penting, tapi distribusinya sangat tidak merata.
6. NCP (Jumlah Makan per Hari)
  *   Mayoritas memilih nilai 3.0.
  *   Data sangat tidak seimbang.
  * Ini menunjukkan perilaku makan masyarakat, tapi mungkin perlu diubah jadi kategori.
7. CH2O (Konsumsi Air per Hari)

  * Ada puncak kuat di nilai 2.0 dan 3.0.
  * Artinya mayoritas minum 2-3 liter per hari.
  * Data tidak seimbang tapi masih bisa dimodelkan.
8. FAF (Frekuensi Aktivitas Fisik)
  * Banyak yang tidak berolahraga (FAF = 0).
  * Puncak berikutnya di sekitar 1.0.
  * Menunjukkan sebagian besar populasi kurang aktif.
9. TUE (Waktu Menggunakan Teknologi untuk Hiburan)
  *   Puncak di sekitar 1.0, lalu banyak yang 0.
  *   Artinya sebagian besar orang menggunakan teknologi 1 jam per hari untuk hiburan.
  * Distribusi mencolok, bisa jadi fitur signifikan.














"""

train["Gender"].value_counts().plot(kind="pie", startangle=90, autopct='%1.1f%%', labels=None)

plt.ylabel("")
plt.legend(train["Gender"].value_counts().index, loc="best")
plt.title("Gender Distribution")

plt.show()

"""Dataset seimbang secara gender:

Female: 50.2%

Male: 49.8%

Distribusi yang seimbang ini baik untuk menghindari bias gender pada model prediktif.
"""

# Menghitung jumlah observasi pada setiap kelas
class_counts = train['NObeyesdad'].value_counts()

# Membuat bar plot horizontal
class_counts.plot(kind='barh')

# Memberikan judul dan label sumbu yang sesuai
plt.title('Jumlah Observasi per Kelas Obesity')
plt.xlabel('Jumlah Observasi')
plt.ylabel('Kelas Obesity')

"""> Insight yang Didapatkan
1.   Distribusi Kelas Tidak Seimbang
Terlihat bahwa beberapa kelas seperti Obesity_Type_III memiliki jumlah observasi yang jauh lebih tinggi dibanding kelas lain seperti Insufficient_Weight atau Overweight_Level_I. Artinya, dataset ini memiliki ketidakseimbangan kelas (class imbalance).
2.   Obesity_Type_III Paling Dominan
Kelas Obesity_Type_III merupakan kelas terbanyak dalam dataset. Hal ini perlu diperhatikan karena model bisa menjadi bias terhadap kelas mayoritas jika ketidakseimbangan ini tidak ditangani.

3. Normal_Weight dan Obesity_Type_II Juga Banyak
Dua kelas besar lainnya adalah Normal_Weight dan Obesity_Type_II, menunjukkan bahwa distribusi berat badan sebagian besar berpusat pada kondisi normal dan obesitas berat.

## Data Preparation

### Feature Engineering

Terdapat fitur yang dapat kita buat dari fitur yang ada yaitu BMI (Body Mass Index). BMI merupakan indikator yang akurat untuk mengukur proporsi tubuh dan menilai risiko penyakit terkait obesitas, seperti diabetes, hipertensi dan penyakit jantung. Dengan mengkalkulasi BMI, dapat ditentukan tingkat keparahan obesitas dan strategi pencegahan serta pengobatan yang tepat. Selain itu, BMI juga membantu mengidentifikasi individu berisiko tinggi, memantau perubahan berat badan dan menentukan kebutuhan nutrisi. Oleh karena itu, pengkalkulasian BMI menjadi salah satu faktor penting dalam prediksi obesitas.
"""

train["BMI"] = train["Weight"] / train["Height"]**2

"""> Menambahkan Fitur BMI
BMI (Body Mass Index) ditambahkan sebagai fitur baru.

Rumus yang digunakan sesuai standar BMI = berat (kg) ÷ tinggi² (m²).

Fitur ini penting karena BMI berhubungan langsung dengan klasifikasi obesitas.

### Splitting Data
"""

X = train.drop("NObeyesdad", axis=1).copy()
y = train["NObeyesdad"].copy()

# splitting the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024)

"""> Split Dataset

Memisahkan fitur (X) dan label (y) dari dataset.

Dataset dibagi menjadi data latih dan data uji dengan rasio 80:20.

random_state=2024 digunakan agar pembagian konsisten (reproducible).

### Standarisasi dan Encoding Data

#### Pemilihan Kolom
Memilih kolom numerik dan kategorikal dari data latih.
"""

numerical_columns = X_train.select_dtypes("number").columns

categorical_columns = X_train.select_dtypes(exclude=["number"]).columns

"""Numerik: Semua kolom bertipe angka.

Kategorikal: Semua kolom non-numerik.

Langkah ini penting untuk:

Menerapkan standarisasi hanya pada data numerik (misal: StandardScaler)

Menerapkan encoding (misal: OneHotEncoder) hanya pada data kategorikal.

#### Pembuatan Preprocessor
Mengubah variabel kategorikal menjadi representasi numerik menggunakan One-Hot Encoding dan mengubah skala fitur numerik menjadi skala seragam menggunakan StandardScaler.
"""

preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), numerical_columns),
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_columns)
    ]
)

"""> Menggabungkan preprocessing untuk fitur numerik dan kategorikal.



StandardScaler() digunakan untuk fitur numerik → menghasilkan nilai berdistribusi normal (mean=0, std=1).

OneHotEncoder() untuk fitur kategorikal → mengubah kategori menjadi vektor biner.

handle_unknown="ignore" → menghindari error jika ada kategori baru saat data uji.

#### Pembuatan Pipeline

Preprocessor sebagai fungsi melakukan proses standarisasi dan encoding digabungkan sebagai Pipeline dari library scikit-learn.
"""

pipeline = Pipeline([
    ("preprocessor", preprocessor)
])

"""Membuat alur preprocessing secara terstruktur.

Pipeline membuat proses lebih ringkas dan reproducible.

#### Transformasi Data

Menerapkan preprocessing pada data latih dan data uji.
"""

X_train_cleaned = pipeline.fit_transform(X_train)
X_test_cleaned = pipeline.transform(X_test)

"""fit_transform pada data latih → belajar parameter dan transformasi.

transform pada data uji → hanya transformasi dengan parameter dari data latih.

Hasilnya adalah data siap masuk ke model machine learning.

## Model Development

### Algoritma Decision Tree
"""

# Membuat dan Melatih Model Decision Tree
# Melatih model Decision Tree
from sklearn.tree import DecisionTreeClassifier

dec_tree = DecisionTreeClassifier(random_state=2024)
dec_tree.fit(X_train_cleaned, y_train)

"""

> Pada tahap ini, membuat objek DecisionTreeClassifier dengan parameter random_state=2024 untuk memastikan hasil yang konsisten. Kemudian model tersebut dilatih menggunakan data pelatihan (X_train_cleaned dan y_train).

"""

# Membuat prediksi
y_pred_train = dec_tree.predict(X_train_cleaned)
y_pred_test = dec_tree.predict(X_test_cleaned)

"""

> Setelah model selesai dilatih, kita menggunakan model tersebut untuk memprediksi label kelas pada data pelatihan dan pengujian. Ini akan digunakan untuk mengevaluasi performa model terhadap data yang dikenal (train) dan tidak dikenal (test).

"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

print("Training Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train))
print("Precision:", precision_score(y_train, y_pred_train, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train, average='weighted'))

"""

> Evaluasi dilakukan terhadap prediksi pada data pelatihan untuk mengetahui apakah model mengalami overfitting (terlalu cocok dengan data training). Metrik yang digunakan adalah:

    *   Accuracy: proporsi prediksi yang benar.
    *   Precision: ketepatan prediksi tiap kelas.
    *   Recall: seberapa banyak kasus positif yang berhasil terdeteksi.
    *   F1-score: harmonisasi antara precision dan recall.


> Overfitting Terdeteksi

    *   Training Accuracy, Precision, Recall, F1-score = 1.0
        * Artinya model sempurna dalam mengenali data latih.
    *   Penurunan cukup signifikan dibanding training (100% vs 83.7%).



> Insight


Model terlalu cocok terhadap data latih dan kurang mampu menggeneralisasi ke data baru. Ini indikasi overfitting — Decision Tree memang rawan mengalami ini jika tidak dilakukan pruning atau pengaturan parameter maksimal.








"""

print("\nTesting Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_test))
print("Precision:", precision_score(y_test, y_pred_test, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_test, average='weighted'))
print("F1-score:", f1_score(y_test, y_pred_test, average='weighted'))

"""

> Evaluasi Performa Umum (Testing Set)


    *   Accuracy: 83.67%  
    *   Precision (weighted): 83.73%
    *   Recall (weighted): 83.67%
    *   F1-score (weighted): 83.71%


>  Insight
Secara keseluruhan, model memiliki kinerja yang cukup baik, tapi masih ada ruang untuk perbaikan terutama untuk kelas-kelas tertentu.





"""

from sklearn.metrics import classification_report

print("\nClassification Report:")
print(classification_report(y_test, y_pred_test))

""">  Insight


      *   Model sangat baik dalam mengklasifikasikan Obesity_Type_III, Obesity_Type_II, dan Insufficient_Weight (F1-score ≥ 0.89).
      *   Overweight_Level_I dan II menjadi kelas yang paling sulit diprediksi (F1-score rendah: 0.68 dan 0.77). Ini bisa disebabkan oleh:
          * Data dari kelas ini saling tumpang tindih (ambiguous).
          * Fitur yang digunakan belum cukup diskriminatif untuk membedakan level overweight.

### Algorima XGBoost
"""

# Melatih model XGBoost
xgb = GradientBoostingClassifier()
xgb.fit(X_train_cleaned, y_train)

"""

> Penjelasan:

      *   Membuat objek model xgb menggunakan algoritma Gradient Boosting dari sklearn.
      *   Melatih model dengan data training (X_train_cleaned, y_train).
      *   Gradient Boosting merupakan teknik ensemble learning yang menggabungkan banyak pohon keputusan secara bertahap (boosting).

"""

# Membuat prediksi
y_pred_train = xgb.predict(X_train_cleaned)
y_pred_test = xgb.predict(X_test_cleaned)

"""

> Penjelasan:


      *   Melakukan prediksi label untuk data training dan data testing menggunakan model XGBoost yang telah dilatih.
      *   y_pred_train: hasil prediksi untuk data training.
      *   y_pred_test: hasil prediksi untuk data testing.

"""

# Menghitung metrik untuk data training
print("Training Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train))
print("Precision:", precision_score(y_train, y_pred_train, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train, average='weighted'))

"""

> Training Metrics:


    *   Accuracy: 92.88%
    *   Precision/Recall/F1-score: ±92.88%



"""

print("\nTesting Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_test))
print("Precision:", precision_score(y_test, y_pred_test, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_test, average='weighted'))
print("F1-score:", f1_score(y_test, y_pred_test, average='weighted'))

"""

> Testing Metrics:


      *  Accuracy: 89.86%
      *  Precision (weighted): 89.00%
      *  Recall (weighted): 89.86%
      *  F1-score (weighted): 89.82%


> Insight

  Model XGBoost menunjukkan peningkatan akurasi sekitar 5% dibanding Decision Tree pada data testing (83.67% ➝ 88.91%). Ini berarti XGBoost lebih mampu melakukan generalisasi dan tidak overfitting separah Decision Tree.



"""

# Menampilkan laporan klasifikasi lengkap
print("\nClassification Report:")
print(classification_report(y_test, y_pred_test))

""">  Insight:


    *   Performa sangat baik untuk kelas Obesity_Type_III dan II (F1-score 0.94–0.97).
    *   Overweight_Level_I dan II masih menjadi tantangan, tapi sudah meningkat dibanding Decision Tree.
    *   Distribusi precision dan recall lebih seimbang antar kelas dibanding model sebelumnya.

### RandomForestClassifier
"""

# Melatih model Random Forest
random_forest = RandomForestClassifier()
random_forest.fit(X_train_cleaned, y_train)

"""

> Melatih model Random Forest


    *   Membuat model klasifikasi menggunakan algoritma Random Forest, yang merupakan ensemble dari beberapa decision tree.
    *   Model ini dilatih menggunakan data training X_train_cleaned dan target y_train.


"""

# Membuat prediksi
y_pred_train = random_forest.predict(X_train_cleaned)
y_pred_test = random_forest.predict(X_test_cleaned)

"""

>Membuat prediksi


    *   Melakukan prediksi hasil klasifikasi untuk:
        * Data training (y_pred_train)
        * Data testing (y_pred_test)


> Insight:

    *   Memisahkan prediksi untuk data train dan test penting untuk melihat apakah model overfitting.






"""

print("Training Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train))
print("Precision:", precision_score(y_train, y_pred_train, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train, average='weighted'))

"""

> Menghitung metrik untuk data training

    *   Menghitung dan menampilkan metrik evaluasi model pada data training.


>Insight:


    *   Skor sempurna menandakan model sangat baik pada data training, tetapi ini bisa mengindikasikan overfitting—performa di data uji perlu dicek.



"""

print("\nTesting Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_test))
print("Precision:", precision_score(y_test, y_pred_test, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_test, average='weighted'))
print("F1-score:", f1_score(y_test, y_pred_test, average='weighted'))

"""

> Menghitung metrik untuk data testing


    *   Menghitung dan mencetak metrik performa pada data testing.


> Insight:


    *   Metrik testing lebih rendah dari training: model menunjukkan tanda overfitting ringan.
    *   Namun, akurasi hampir 90% menunjukkan performa yang masih sangat baik dan stabil.



"""

# Menampilkan laporan klasifikasi lengkap
print("\nClassification Report:")
print(classification_report(y_test, y_pred_test))

"""> Menampilkan laporan klasifikasi lengkap


    *   Menampilkan performa model untuk setiap kelas dalam bentuk:
        *   Precision, Recall, F1-score, dan Jumlah data (support)


> Insight dari Report:


    *   Semua kelas mendapatkan F1-score antara 0.87 – 0.91, artinya model bekerja konsisten untuk tiap kategori obesitas dan berat badan.
    *   Tidak ada kelas yang tertinggal jauh performanya.
    *   Model dapat membedakan setiap kelas dengan baik, termasuk kelas yang mirip seperti Obesity_Type_I dan Overweight_Level_II.

### Support Vector Machine (SVM)
"""

# Import library yang diperlukan
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

svm = SVC(kernel='rbf', random_state=2024)
svm.fit(X_train_cleaned, y_train)

"""

> Membuat & Melatih Model SVM


    *   Membuat model SVM dengan kernel RBF (Radial Basis Function) yang cocok untuk data non-linear.
    *   Model dilatih menggunakan X_train_cleaned dan y_train.



"""

y_pred_train_svm = svm.predict(X_train_cleaned)
y_pred_test_svm = svm.predict(X_test_cleaned)

"""

> Prediksi

    *   Melakukan prediksi label untuk data training dan testing menggunakan model SVM.


> Insight:

    *   Nantinya, prediksi ini digunakan untuk mengevaluasi apakah model overfitting atau generalisasi dengan baik.








"""

print("SVM Classification Report:")
print("\nTraining Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train_svm))
print("Precision:", precision_score(y_train, y_pred_train_svm, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train_svm, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train_svm, average='weighted'))

"""

> Evaluasi pada Data Training

Skor training sangat tinggi (90%) namun tidak 100% seperti Random Forest → ini mengindikasikan model tidak overfitting parah, bagus untuk generalisasi.

"""

print("\nTesting Metrics:")
print("\nTesting Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_test_svm, ))
print("Precision:", precision_score(y_test, y_pred_test_svm, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_test_svm, average='weighted'))
print("F1-score:", f1_score(y_test, y_pred_test_svm, average='weighted'))

"""

> Insight:


    *  Performa test hampir 90% dan mendekati training → menandakan model stabil dan tidak overfitting.
    *  Skor ini sedikit lebih baik daripada Random Forest pada dataset ini.




"""

print(classification_report(y_test, y_pred_test_svm))

"""> Insight dari Laporan:


    *   Precision, Recall, dan F1-score berkisar 0.87–0.91 di tiap kelas → konsisten dan merata.
    *   Tidak ada kelas yang tertinggal performanya, termasuk kelas minoritas seperti Obesity_Type_I dan Insufficient_Weight.
    *   Model mampu membedakan semua kelas obesitas & berat badan dengan akurasi dan presisi tinggi.

### Logistic Regression
"""

log_reg = LogisticRegression(multi_class='multinomial', max_iter=1000)
log_reg.fit(X_train_cleaned, y_train)

"""

> Penjelasan Kode


    *   log_reg = LogisticRegression(...): Baris ini membuat (menginisialisasi) sebuah objek model klasifikasi yang disebut Regresi Logistik (Logistic Regression).
        *   multi_class='multinomial': Parameter ini penting karena menunjukkan bahwa masalah klasifikasi ini memiliki lebih dari dua kelas target (multi-kelas), dan model harus menggunakan strategi "multinomial" untuk menanganinya. Ini berarti model akan secara langsung memprediksi probabilitas untuk setiap kelas.
        *  max_iter=1000: Parameter ini menetapkan jumlah maksimum iterasi yang diizinkan bagi algoritma optimasi internal model untuk mencoba menemukan solusi terbaik (konvergen). Nilai 1000 cukup tinggi dan biasanya cukup untuk sebagian besar kasus agar model konvergen.
    *   log_reg.fit(X_train_cleaned, y_train): Baris ini "melatih" model (log_reg) menggunakan data latih.
        * X_train_cleaned: Ini adalah data fitur (variabel independen) dari set pelatihan Anda, yang tampaknya sudah melalui tahap pembersihan atau prapemrosesan (ditandai dengan _cleaned).
        * y_train: Ini adalah label kelas (variabel dependen/target) yang sesuai untuk data X_train_cleaned. Model belajar memetakan fitur di X_train_cleaned ke label di y_train.



> Insight

menyiapkan model Regresi Logistik yang dikonfigurasi untuk menangani banyak kelas target dan kemudian melatihnya menggunakan data pelatihan yang sudah disiapkan. Hasil dari sel ini adalah model (log_reg) yang telah "belajar" pola dari data latih.

"""

y_pred_train_log = log_reg.predict(X_train_cleaned)
y_pred_test_log = log_reg.predict(X_test_cleaned)

"""

> Penjelasan Kode


    *   y_pred_train_log = log_reg.predict(X_train_cleaned): Setelah model dilatih, baris ini menggunakan model (log_reg) untuk membuat prediksi kelas pada data latih itu sendiri (X_train_cleaned). Hasil prediksi disimpan dalam variabel y_pred_train_log.
    *   y_pred_test_log = log_reg.predict(X_test_cleaned): Baris ini menggunakan model yang sama untuk membuat prediksi kelas pada data uji (X_test_cleaned). Data uji adalah data yang belum pernah dilihat model selama pelatihan. Hasil prediksi disimpan dalam variabel y_pred_test_log.


> Insight

untuk mendapatkan prediksi dari model yang sudah dilatih, baik pada data yang digunakan untuk melatihnya (untuk memeriksa seberapa baik model "menghafal" data latih) maupun pada data baru (untuk mengevaluasi kemampuan generalisasi model).





"""

print("\nLogistic Regression Classification Report:")
print("\nTraining Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train_log))
print("Precision:", precision_score(y_train, y_pred_train_log, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train_log, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train_log, average='weighted'))

"""

> Insight

Metrik pada data latih menunjukkan seberapa baik model cocok dengan data yang digunakan untuk melatihnya. Di sini, akurasi, presisi, recall, dan F1-score semuanya sekitar 86-87%. Ini menunjukkan model telah belajar dengan baik dari data latih. Namun, performa tinggi pada data latih saja tidak cukup; kita perlu melihat performa pada data uji untuk memastikan model tidak overfitting (terlalu menghafal data latih dan tidak bisa generalisasi ke data baru).
"""

print("\nTesting Metrics:")
print("\nTesting Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_test_log))
print("Precision:", precision_score(y_test, y_pred_test_log, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_test_log, average='weighted'))
print("F1-score:", f1_score(y_test, y_pred_test_log, average='weighted'))

"""
> Insight

Performa pada data uji sangat penting. Di sini, metriknya (akurasi ~86.5%, presisi ~86.4%, recall ~86.5%, F1-score ~86.4%) sangat mirip dengan metrik pada data latih. Ini adalah hasil yang sangat baik! Artinya, model memiliki kemampuan generalisasi yang baik dan tidak mengalami overfitting yang signifikan. Performa model konsisten antara data latih dan data uji.



"""

print(classification_report(y_test, y_pred_test_log))

"""> Insight

    *   Performa Per Kelas: Laporan ini memberikan wawasan mendalam. Kita bisa melihat bahwa model sangat baik dalam mengidentifikasi Obesity_Type_II dan Obesity_Type_III (F1-score 0.97 dan 0.99). Model juga cukup baik untuk Insufficient_Weight (0.92) dan Normal_Weight / Obesity_Type_I (keduanya ~0.84-0.89). Namun, performa model sedikit lebih rendah untuk Overweight_Level_I (F1-score 0.73) dan Overweight_Level_II (F1-score 0.78). Ini menunjukkan bahwa model mungkin sedikit kesulitan membedakan kedua kelas ini dibandingkan dengan kelas lainnya.
    *   Rata-rata: weighted avg (rata-rata tertimbang berdasarkan jumlah sampel per kelas) F1-score adalah 0.86, yang konsisten dengan hasil di sel [44]. macro avg (rata-rata tanpa pembobotan) F1-score sedikit lebih tinggi (0.87), menunjukkan bahwa performa pada kelas-kelas yang lebih sedikit sampelnya (seperti Overweight Level I/II) tidak terlalu menurunkan rata-rata jika semua kelas dianggap sama penting.
    *   Support: Menunjukkan jumlah data uji untuk setiap kelas. Informasi ini penting untuk konteks; metrik untuk kelas dengan support sangat kecil mungkin kurang dapat diandalkan. Dalam kasus ini, jumlah sampel per kelas tampak cukup seimbang, meskipun ada variasi.

### Lightgbm
"""

pip install lightgbm

import lightgbm as lgb
lgb_model = lgb.LGBMClassifier()
lgb_model.fit(X_train_cleaned, y_train)

"""

> Insight

Sel ini mengganti model Logistic Regression dengan LightGBM, sebuah model berbasis tree ensemble (kumpulan pohon keputusan) yang seringkali lebih kuat dan akurat untuk data tabular, meskipun bisa lebih rentan terhadap overfitting jika tidak diatur dengan baik. Model dilatih menggunakan data yang sama seperti sebelumnya.

"""

y_pred_train_lgb = lgb_model.predict(X_train_cleaned)
y_pred_test_lgb = lgb_model.predict(X_test_cleaned)

"""

> Insight

Sama seperti alur sebelumnya, sel ini menghasilkan prediksi dari model LightGBM untuk data latih dan data uji, yang akan digunakan untuk evaluasi performa.

"""

print("\nLightGBM Classification Report:")
print("\nTraining Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train_lgb))
print("Precision:", precision_score(y_train, y_pred_train_lgb, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train_lgb, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train_lgb, average='weighted'))

"""

> Insight

Performa model LightGBM pada data latih sangat tinggi, dengan semua metrik mencapai sekitar 98%. Ini menunjukkan bahwa model LightGBM (dengan parameter default) mampu mempelajari pola dalam data latih dengan sangat baik, bahkan lebih baik daripada Logistic Regression. Namun, skor setinggi ini pada data latih seringkali menjadi indikasi awal adanya overfitting.

"""

print("\nTesting Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_test_lgb))
print("Precision:", precision_score(y_test, y_pred_test_lgb, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_test_lgb, average='weighted'))
print("F1-score:", f1_score(y_test, y_pred_test_lgb, average='weighted'))

"""

> Insight

Performa LightGBM pada data uji (sekitar 90% untuk semua metrik) secara signifikan lebih baik daripada performa Logistic Regression (yang sekitar 86%). Ini menunjukkan bahwa LightGBM mampu menangkap pola yang lebih kompleks dalam data yang menghasilkan prediksi lebih akurat pada data baru. Namun, perhatikan adanya penurunan performa dari data latih (98%) ke data uji (90%). Kesenjangan ini mengkonfirmasi adanya overfitting. Meskipun model ini lebih baik secara keseluruhan pada data uji, ia terlalu "menghafal" data latih.

"""

print(classification_report(y_test, y_pred_test_lgb))

"""> Insight


    *   Peningkatan Per Kelas:
        * Dibandingkan dengan Logistic Regression, LightGBM meningkatkan F1-score untuk hampir semua kelas. Yang paling signifikan adalah peningkatan untuk kelas Overweight_Level_I (dari 0.73 menjadi 0.81) dan Overweight_Level_II (dari 0.78 menjadi 0.86), yang merupakan kelas terlemah pada model sebelumnya. Kelas Obesity_Type_III bahkan mencapai F1-score 1.00 (sempurna dalam konteks metrik ini pada data uji).
    *   Konsistensi Rata-rata:
        * weighted avg F1-score adalah 0.90, mengkonfirmasi hasil dari sel [51] dan peningkatan dari Logistic Regression.
    *   Kemampuan Model:
        * Laporan ini menunjukkan bahwa kemampuan LightGBM untuk membangun model yang lebih kompleks (dari gabungan banyak pohon keputusan) memungkinkannya untuk membedakan kelas-kelas yang sulit dengan lebih baik daripada model linier seperti Logistic Regression.

### Evaluasi Model

### **Hasil Evaluasi Model**

1. **Decision Tree**
- Akurasi, presisi, recall, dan F1-score pada data pelatihan mencapai 100%.
- Hasil pengujian menunjukkan akurasi, presisi, recall, dan F1-score sebesar 84%.
- Terdapat indikasi overfitting yang signifikan, terlihat dari selisih besar antara hasil pelatihan dan pengujian.
- Presisi dan recall seimbang pada pelatihan dan pengujian.
- F1-score pada level sedang, menunjukkan tingkat akurasi model yang cukup baik.

2. **XGBoost**
- Performa pelatihan mencatat akurasi, presisi, recall, dan F1-score sebesar 92%.
- Hasil pengujian menunjukkan akurasi dan metrik lainnya di angka 90%.
- Meskipun terdapat sedikit overfitting, kinerja pengujian tetap sangat solid.
- Presisi dan recall konsisten, baik dalam pelatihan maupun pengujian.
- F1-score tinggi menunjukkan akurasi model yang sangat baik.

3. **Random Forest**
- Model menunjukkan performa sempurna di pelatihan (100% untuk semua metrik).
- Pengujian menghasilkan akurasi dan metrik lainnya sebesar 90%.
- Terdapat kecenderungan overfitting, namun performa pada data pengujian tetap impresif.
- Presisi dan recall tetap seimbang pada kedua fase.
- F1-score tinggi menandakan model memiliki tingkat akurasi yang sangat baik.

4. **SVM (Support Vector Machine)**
- Akurasi, presisi, recall, dan F1-score pada pelatihan mencapai 90%.
- Hasil pengujian sedikit lebih rendah, yakni 88%.
- Kinerja relatif stabil antara pelatihan dan pengujian.
- Presisi dan recall tetap proporsional.
- F1-score tergolong sedang, menunjukkan performa model yang cukup solid.

5. **Logistic Regression**
- Akurasi pelatihan sebesar 86.83%, dan pengujian sebesar 87%.
- Konsistensi performa terlihat antara data pelatihan dan pengujian.
- Presisi dan recall seimbang di kedua fase.
- F1-score tinggi, mencerminkan akurasi model yang baik.

6. **LightGBM**
- Performa pelatihan sangat tinggi (99% untuk semua metrik).
- Akurasi dan metrik lainnya pada pengujian berada di kisaran 90%.
- Meskipun menunjukkan tanda overfitting, model tetap memberikan hasil pengujian yang kuat.
- Presisi dan recall terjaga baik pada kedua fase.
- F1-score tinggi, yang menunjukkan model ini sangat akurat.

**Catatan:** Seluruh nilai akurasi, presisi, recall, dan F1-score telah dibulatkan untuk kemudahan interpretasi.

---

### **Kesimpulan Evaluasi Model**

- **Performa Terbaik:** Model XGBoost, Random Forest, dan LightGBM mencatatkan hasil tertinggi untuk seluruh metrik pengujian. Namun, LightGBM cenderung overfit, sedangkan XGBoost menunjukkan keseimbangan terbaik antara pelatihan dan pengujian, dengan akurasi dan metrik lainnya mencapai 90%.
- **Overfitting:** Decision Tree, Random Forest, dan LightGBM menunjukkan gejala overfitting, ditandai dengan performa pelatihan yang terlalu tinggi dibanding pengujian.

---

### **Implikasi terhadap Business Understanding**

1. **Problem Statement:**
   - Model prediktif telah mencapai akurasi di atas 85%, yang berarti target yang ditentukan berhasil dipenuhi.

2. **Goals:**
   - Model XGBoost dan LightGBM mampu melampaui target performa yang ditetapkan, dengan akurasi masing-masing mencapai 90%.

3. **Solution Statements:**
   - Evaluasi terhadap beberapa model machine learning menghasilkan solusi optimal, yaitu melalui penerapan XGBoost dan LightGBM.

---

### **Rekomendasi**

Berdasarkan evaluasi menyeluruh, model **XGBoost** direkomendasikan untuk digunakan dalam sistem prediksi obesitas. Model ini tidak hanya mencapai performa terbaik, tetapi juga menunjukkan konsistensi yang tinggi antara hasil pelatihan dan pengujian, menjadikannya pilihan paling andal di antara semua algoritma yang diuji.
"""